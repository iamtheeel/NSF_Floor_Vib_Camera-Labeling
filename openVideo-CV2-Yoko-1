####
# Yoko Lu
# SFSU STARS Summer 2025
# Dr J Lab
###
# Opens a video file in OpenCV and shows frame processing timing without display
####

# Built-ins
import time

# Third-party
import cv2  # pip install opencv-python
import pytesseract  # pip install pytesseract

# === SETTINGS ===
dir = '/Volumes/MY PASSPORT/Stars_day1Data/'
file = 's2_B8A44FC4B25F_6-3-2025_4-00-20 PM.asf'
filename = f"{dir}{file}"  # Full path to the video file

# === Dummy function (you can modify as needed) ===
def compare_video_fps(video1_fps, video2_fps):
    print(f"Video 1 FPS: {video1_fps} Hz")
    print(f"Video 2 FPS: {video2_fps} Hz")

# === OPEN VIDEO ===
videoObject = cv2.VideoCapture(filename)

if not videoObject.isOpened():
    print(f"‚ùå Error opening video file: {filename}")
    exit()

print(f"{dir=}, {filename=}")

# === Call FPS comparison function ===
compare_video_fps("First video fps,", "Second video fps")
video2_fps = 5  # Example value

# === VIDEO METADATA ===
fps = videoObject.get(cv2.CAP_PROP_FPS)
fCount = int(videoObject.get(cv2.CAP_PROP_FRAME_COUNT))
w = int(videoObject.get(cv2.CAP_PROP_FRAME_WIDTH))
h = int(videoObject.get(cv2.CAP_PROP_FRAME_HEIGHT))
frame_count = fCount if fCount > 0 else 0

print(f"‚úÖ Loaded: {filename}")
print(f"üéûÔ∏è FPS: {fps:.2f} Hz")
print(f"üìä Total Frames: {frame_count}, Type: {type(frame_count)}")
print(f"üñºÔ∏è Width: {w}, Height: {h}")

# === TIMING ===
idealFrameDelay_ms = 1000 / fps if fps > 0 else 33.33
print(f"‚è±Ô∏è Target Frame Time: {idealFrameDelay_ms:.2f} ms")

# === DISPLAY SETTINGS ===
dispFact = 2
displayRes = (int(w / dispFact), int(h / dispFact))

# === FRAME LOOP ===
for i in range(frame_count):
    startTime = time.time()

    success, frame = videoObject.read()
    if not success:
        print(f"‚ùå Failed to read frame {i}")
        break

    # === GRAYSCALE + BLUR ===
    grayFrame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    blurred = cv2.GaussianBlur(grayFrame, (5, 5), 1.4)

    # === CANNY ===
    edges = cv2.Canny(blurred, 10, 10)

    # === LAPLACIAN ===
    lap = cv2.Laplacian(grayFrame, cv2.CV_64F)
    lap = cv2.convertScaleAbs(lap)

    # === OCR: Extract time from original frame ===
    timestamp_crop = frame[0:100, 0:400]  # Adjust size if needed
    gray = cv2.cvtColor(timestamp_crop, cv2.COLOR_BGR2GRAY)
    _, thresh = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY)
    scaled = cv2.resize(thresh, None, fx=2, fy=2, interpolation=cv2.INTER_LINEAR)
    dateTime_str = pytesseract.image_to_string(scaled)

    if dateTime_str.strip():
        print(f"[FRAME {i:04d}] OCR Timestamp: \"{dateTime_str.strip()}\"")
    else:
        print(f"[FRAME {i:04d}] OCR Timestamp: [no text detected]")

    # === TIMING ===
    endTime = time.time()
    processingTime_ms = 1000 * (endTime - startTime)q
    actualWaitTime_ms = max(1, idealFrameDelay_ms - processingTime_ms)
    print(f"[FRAME {i:04d}] Proc Time: {processingTime_ms:.2f} ms | Delay: {actualWaitTime_ms:.2f} ms")

# === CLEANUP ===
videoObject.release()
cv2.destroyAllWindows()
